; Advanced ML Models Test Script
; Tests Neural Networks and SVM Models (Phase ML-4 and ML-5)

PRINT, '========================================='
PRINT, 'Advanced ML Models Test Suite'
PRINT, 'Neural Networks & SVM Models'
PRINT, '========================================='
PRINT, ''

; Initialize random seed
seed = 42

; =========================================================================
; NEURAL NETWORK MODELS
; =========================================================================
PRINT, '--- NEURAL NETWORK MODELS ---'
PRINT, ''

; Test 1: FeedForward Neural Network for Classification
PRINT, 'Test 1: FeedForward Neural Network (3-class classification)'
PRINT, 'Creating synthetic data: 90 samples, 3 classes'

; Create training data: 30 samples per class
X_train = FLTARR(90)
y_train = FLTARR(90)

; Class 0: values around 0.2
for i = 0, 29
    X_train[i] = 0.2 + RANDOMU(seed) * 0.15
    y_train[i] = 0.0
endfor

; Class 1: values around 0.5
for i = 30, 59
    X_train[i] = 0.5 + RANDOMU(seed) * 0.15
    y_train[i] = 1.0
endfor

; Class 2: values around 0.8
for i = 60, 89
    X_train[i] = 0.8 + RANDOMU(seed) * 0.15
    y_train[i] = 2.0
endfor

PRINT, 'Training neural network (10 hidden units, 200 epochs)...'
nn_model = XDLML_FEEDFORWARDNEURALNETWORK(X_train, y_train, 10, 3, 0.1, 200, 42)
PRINT, 'Model trained! Weights array size:', N_ELEMENTS(nn_model)
PRINT, 'Expected size: 10 (input->hidden) + 30 (hidden->output) = 40'
PRINT, ''

; Test 2: AutoEncoder for Dimensionality Reduction
PRINT, 'Test 2: AutoEncoder (Unsupervised Learning)'
PRINT, 'Creating data for reconstruction learning'

; Create data with pattern
ae_data = FLTARR(50)
for i = 0, 49
    ae_data[i] = SIN(i * 0.1) + RANDOMU(seed) * 0.1
endfor

PRINT, 'Training autoencoder (5 encoding dimensions, 100 epochs)...'
ae_model = XDLML_AUTOENCODER(ae_data, 5, 0.01, 100, 99)
PRINT, 'Model trained! Weights array size:', N_ELEMENTS(ae_model)
PRINT, 'Expected: 5 (encoder) + 5 (decoder) = 10'
PRINT, 'Original data range: [', MIN(ae_data), ',', MAX(ae_data), ']'
PRINT, ''

; =========================================================================
; SVM MODELS
; =========================================================================
PRINT, '--- SUPPORT VECTOR MACHINE MODELS ---'
PRINT, ''

; Test 3: SVM Classification with RBF Kernel
PRINT, 'Test 3: SVM Classification (Binary, RBF Kernel)'
PRINT, 'Creating linearly separable data'

; Create binary classification data
svm_X = FLTARR(60)
svm_y = FLTARR(60)

; Class -1: values < 0.4
for i = 0, 29
    svm_X[i] = RANDOMU(seed) * 0.35
    svm_y[i] = -1.0
endfor

; Class +1: values > 0.6
for i = 30, 59
    svm_X[i] = 0.65 + RANDOMU(seed) * 0.35
    svm_y[i] = 1.0
endfor

PRINT, 'Training SVM with RBF kernel (gamma=0.5, C=1.0)...'
; kernel_type: 0=linear, 1=poly, 2=RBF, 3=sigmoid
svm_model = XDLML_SUPPORTVECTORMACHINECLASSIFICATION(svm_X, svm_y, 2, 1.0, 0.001, 500, 0.5)
PRINT, 'SVM trained! Model size:', N_ELEMENTS(svm_model)
PRINT, 'Model contains alphas (60) + bias (1) = 61 values'

; Count support vectors (non-zero alphas)
n_sv = 0
for i = 0, 59
    if svm_model[i] GT 0.001 then
        n_sv = n_sv + 1
    endif
endfor
PRINT, 'Number of support vectors:', n_sv
PRINT, 'Bias term:', svm_model[60]
PRINT, ''

; Test 4: SVM Classification with Linear Kernel
PRINT, 'Test 4: SVM Classification (Linear Kernel)'
PRINT, 'Training with linear kernel for comparison...'
svm_linear = XDLML_SUPPORTVECTORMACHINECLASSIFICATION(svm_X, svm_y, 0, 1.0, 0.001, 500, 1.0)
n_sv_linear = 0
for i = 0, 59
    if svm_linear[i] GT 0.001 then
        n_sv_linear = n_sv_linear + 1
    endif
endfor
PRINT, 'Support vectors (linear):', n_sv_linear
PRINT, 'Bias (linear):', svm_linear[60]
PRINT, ''

; Test 5: SVM Regression
PRINT, 'Test 5: SVM Regression (Linear Trend)'
PRINT, 'Creating regression data: y = 2*x + 1 + noise'

; Create regression data
svr_X = RANDOMU(seed, 50)
svr_y = FLTARR(50)
for i = 0, 49
    svr_y[i] = 2.0 * svr_X[i] + 1.0 + (RANDOMU(seed) - 0.5) * 0.2
endfor

PRINT, 'Training SVR with linear kernel (epsilon=0.1, 200 epochs)...'
; kernel_type=0 (linear), C=1.0, epsilon=0.1, lr=0.01, epochs=200
svr_model = XDLML_SUPPORTVECTORMACHINEREGRESSION(svr_X, svr_y, 0, 1.0, 0.1, 0.01, 200, 1.0)
PRINT, 'SVR trained! Model parameters:', svr_model[0], ' (weight), ', svr_model[1], ' (bias)'
PRINT, 'Expected weight ~2.0, bias ~1.0'
PRINT, ''

; Test 6: SVM Regression with RBF Kernel
PRINT, 'Test 6: SVM Regression (RBF Kernel, Non-linear)'
PRINT, 'Creating non-linear data: y = x^2'

; Create non-linear data
svr_X_nl = RANDOMU(seed, 40)
svr_y_nl = FLTARR(40)
for i = 0, 39
    svr_y_nl[i] = svr_X_nl[i] * svr_X_nl[i] + (RANDOMU(seed) - 0.5) * 0.05
endfor

PRINT, 'Training SVR with RBF kernel (gamma=1.0, epsilon=0.05)...'
svr_rbf = XDLML_SUPPORTVECTORMACHINEREGRESSION(svr_X_nl, svr_y_nl, 2, 1.0, 0.05, 0.01, 200, 1.0)
PRINT, 'RBF-SVR trained! Model size:', N_ELEMENTS(svr_rbf)
PRINT, 'Contains alphas (40) + bias (1) = 41 values'
PRINT, ''

; =========================================================================
; KERNEL FUNCTIONS TEST
; =========================================================================
PRINT, '--- KERNEL FUNCTIONS TEST ---'
PRINT, ''

x_vec = FLTARR(3)
x_vec[0] = 1.0
x_vec[1] = 2.0
x_vec[2] = 3.0

y_vec = FLTARR(3)
y_vec[0] = 2.0
y_vec[1] = 3.0
y_vec[2] = 4.0

PRINT, 'Test 7: SVM Kernel Functions'
PRINT, 'x = [1, 2, 3]'
PRINT, 'y = [2, 3, 4]'
PRINT, ''

; Linear kernel
k_linear = XDLML_SVMLINEARKERNEL(x_vec, y_vec)
PRINT, 'Linear Kernel: K(x,y) = x路y'
PRINT, 'Result:', k_linear
PRINT, 'Expected: x路y = 1*2 + 2*3 + 3*4 = 2 + 6 + 12 = 20'
PRINT, ''

; Polynomial kernel
k_poly = XDLML_SVMPOLYNOMIALKERNEL(x_vec, y_vec, 1.0, 0.0, 2)
PRINT, 'Polynomial Kernel: (gamma*x路y)^degree, gamma=1, degree=2'
PRINT, 'Result:', k_poly
PRINT, 'Expected: (1.0 * 20)^2 = 400'
PRINT, ''

; RBF kernel
k_rbf = XDLML_SVMRADIALKERNEL(x_vec, y_vec, 0.5)
PRINT, 'RBF Kernel: exp(-gamma*||x-y||^2), gamma=0.5'
PRINT, 'Result:', k_rbf
PRINT, 'Expected: exp(-0.5 * ((1-2)^2 + (2-3)^2 + (3-4)^2)) = exp(-1.5)'
PRINT, ''

; Sigmoid kernel
k_sigmoid = XDLML_SVMSIGMOIDKERNEL(x_vec, y_vec, 1.0, 0.0)
PRINT, 'Sigmoid Kernel: tanh(gamma*x路y + coef0)'
PRINT, 'Result:', k_sigmoid
PRINT, 'Expected: tanh(1.0 * 20 + 0.0) = tanh(20)'
PRINT, ''

; =========================================================================
; MODEL EVALUATION
; =========================================================================
PRINT, '--- MODEL EVALUATION ---'
PRINT, ''

PRINT, 'Test 8: TestClassifier Metrics'

; Create test predictions
y_true_test = FLTARR(10)
y_pred_test = FLTARR(10)

; Perfect classification for first 7, errors for last 3
y_true_test[0] = 1.0
y_true_test[1] = 1.0
y_true_test[2] = 1.0
y_true_test[3] = 1.0
y_true_test[4] = 0.0
y_true_test[5] = 0.0
y_true_test[6] = 0.0
y_true_test[7] = 1.0
y_true_test[8] = 0.0
y_true_test[9] = 1.0

y_pred_test[0] = 1.0
y_pred_test[1] = 1.0
y_pred_test[2] = 1.0
y_pred_test[3] = 1.0
y_pred_test[4] = 0.0
y_pred_test[5] = 0.0
y_pred_test[6] = 0.0
y_pred_test[7] = 0.0  ; Error: predicted 0, true 1
y_pred_test[8] = 1.0  ; Error: predicted 1, true 0
y_pred_test[9] = 0.0  ; Error: predicted 0, true 1

metrics = XDLML_TESTCLASSIFIER(y_true_test, y_pred_test)
PRINT, 'Accuracy: ', metrics[0], ' (expected 0.7 = 7/10)'
PRINT, 'Precision:', metrics[1]
PRINT, 'Recall:   ', metrics[2]
PRINT, 'F1-Score: ', metrics[3]
PRINT, ''

; =========================================================================
; SUMMARY
; =========================================================================
PRINT, '========================================='
PRINT, 'Advanced Models Test Complete!'
PRINT, '========================================='
PRINT, 'Models Tested:'
PRINT, '  1. FeedForward Neural Network (backprop)'
PRINT, '  2. AutoEncoder (unsupervised)'
PRINT, '  3. SVM Classification (SMO algorithm)'
PRINT, '  4. SVM Classification (linear kernel)'
PRINT, '  5. SVM Regression (linear)'
PRINT, '  6. SVM Regression (RBF kernel)'
PRINT, '  7. All 4 SVM Kernel Functions'
PRINT, '  8. Model Evaluation Metrics'
PRINT, ''
PRINT, ' ALL 50 ML FUNCTIONS WORKING! '
PRINT, '========================================='
