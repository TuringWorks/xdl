; Comprehensive ML Functions Test Suite
; Tests all implemented ML functions in XDL
; Phases: ML-1 (Foundation), ML-2 (Activations/Losses), ML-3 (Optimizers)

PRINT, '========================================='
PRINT, 'XDL Machine Learning Functions Test Suite'
PRINT, '========================================='
PRINT, ''

; =========================================================================
; PHASE ML-1: FOUNDATION - Data Utilities and Normalizers
; =========================================================================
PRINT, '--- PHASE ML-1: FOUNDATION ---'
PRINT, ''

; Test 1: XDLML_PARTITION
PRINT, 'Test 1: XDLML_Partition (Train/Test Split)'
partition = XDLML_PARTITION(100, 0.8)
n_train = 0
train_indices = WHERE(partition, n_train)
PRINT, 'Training samples:', n_train, ' (expected 80)'
PRINT, 'Test samples:', 100 - n_train, ' (expected 20)'
PRINT, ''

; Test 2: XDLML_SHUFFLE
PRINT, 'Test 2: XDLML_Shuffle (Data Shuffling)'
indices = XDLML_SHUFFLE(10, 42)
PRINT, 'Shuffled indices (seed=42):', indices[0], indices[1], indices[2], indices[9]
; Reproducibility test
indices2 = XDLML_SHUFFLE(10, 42)
matches = (indices[0] EQ indices2[0]) AND (indices[1] EQ indices2[1])
PRINT, 'Reproducibility test:', matches, ' (expected 1)'
PRINT, ''

; Test 3-7: Normalizers
test_data = FINDGEN(10) * 10.0  ; [0, 10, 20, ..., 90]

PRINT, 'Test 3: XDLML_LinearNormalizer (scale=0.5, offset=10)'
norm_linear = XDLML_LINEAR_NORMALIZER(test_data, 0.5, 10.0)
PRINT, 'First 3 values:', norm_linear[0], norm_linear[1], norm_linear[2]
PRINT, 'Expected: 10.0, 15.0, 20.0'
PRINT, ''

PRINT, 'Test 4: XDLML_RangeNormalizer (Min-Max to [0,1])'
norm_range = XDLML_RANGE_NORMALIZER(test_data)
PRINT, 'Min value:', norm_range[0], ' (expected 0.0)'
PRINT, 'Max value:', norm_range[9], ' (expected 1.0)'
PRINT, 'Mid value:', norm_range[4], ' (expected 0.44)'
PRINT, ''

PRINT, 'Test 5: XDLML_VarianceNormalizer (Z-score)'
norm_variance = XDLML_VARIANCE_NORMALIZER(test_data)
PRINT, 'Mean should be ~0:', norm_variance[0] + norm_variance[5] + norm_variance[9]
PRINT, 'First value:', norm_variance[0]
PRINT, ''

PRINT, 'Test 6: XDLML_TanHNormalizer'
small_data = FINDGEN(5) - 2.0  ; [-2, -1, 0, 1, 2]
norm_tanh = XDLML_TANH_NORMALIZER(small_data)
PRINT, 'tanh(0):', norm_tanh[2], ' (expected 0.0)'
PRINT, 'tanh(1):', norm_tanh[3], ' (expected 0.76)'
PRINT, ''

PRINT, 'Test 7: XDLML_UnitNormalizer (L2 normalization)'
vec_data = FLTARR(3)
vec_data[0] = 3.0
vec_data[1] = 4.0
vec_data[2] = 0.0
norm_unit = XDLML_UNIT_NORMALIZER(vec_data)
; L2 norm of [3, 4, 0] = 5, so normalized = [0.6, 0.8, 0.0]
PRINT, 'Normalized [3,4,0]:', norm_unit[0], norm_unit[1], norm_unit[2]
PRINT, 'Expected: 0.6, 0.8, 0.0'
PRINT, ''

; Test 8: XDLML_KMEANS
PRINT, 'Test 8: XDLML_KMeans (K-means clustering)'
; Create 3 well-separated clusters
cluster_data = FLTARR(30)
FOR i=0, 9 DO BEGIN
    cluster_data[i] = FINDGEN(1) * 2 + 10.0  ; Around 10
endfor
FOR i=10, 19 DO BEGIN
    cluster_data[i] = FINDGEN(1) * 2 + 50.0  ; Around 50
endfor
FOR i=20, 29 DO BEGIN
    cluster_data[i] = FINDGEN(1) * 2 + 90.0  ; Around 90
endfor
km_result = XDLML_KMEANS(cluster_data, 3, 50, 42)
PRINT, 'First cluster labels:', km_result[0], km_result[5], km_result[9]
PRINT, 'Second cluster labels:', km_result[10], km_result[15], km_result[19]
PRINT, 'Third cluster labels:', km_result[20], km_result[25], km_result[29]
PRINT, ''

; =========================================================================
; PHASE ML-2: ACTIVATION FUNCTIONS
; =========================================================================
PRINT, '--- PHASE ML-2: ACTIVATION FUNCTIONS ---'
PRINT, ''

act_test_data = FLTARR(5)
act_test_data[0] = -2.0
act_test_data[1] = -0.5
act_test_data[2] = 0.0
act_test_data[3] = 0.5
act_test_data[4] = 2.0

PRINT, 'Test 9: Identity Activation'
act_identity = XDLMLAF_IDENTITY(act_test_data)
PRINT, 'Identity[-2, -0.5, 0, 0.5, 2]:', act_identity[0], act_identity[2], act_identity[4]
PRINT, ''

PRINT, 'Test 10: Binary Step Activation'
act_binary = XDLMLAF_BINARYSTEP(act_test_data)
PRINT, 'BinaryStep[-2, 0, 2]:', act_binary[0], act_binary[2], act_binary[4]
PRINT, 'Expected: 0, 1, 1'
PRINT, ''

PRINT, 'Test 11: Logistic (Sigmoid) Activation'
act_logistic = XDLMLAF_LOGISTIC(act_test_data)
PRINT, 'Sigmoid(0):', act_logistic[2], ' (expected 0.5)'
PRINT, 'Sigmoid(2):', act_logistic[4], ' (expected 0.88)'
PRINT, ''

PRINT, 'Test 12: TanH Activation'
act_tanh = XDLMLAF_TANH(act_test_data)
PRINT, 'tanh(0):', act_tanh[2], ' (expected 0.0)'
PRINT, 'tanh(2):', act_tanh[4], ' (expected 0.96)'
PRINT, ''

PRINT, 'Test 13: ReLU Activation'
act_relu = XDLMLAF_RELU(act_test_data)
PRINT, 'ReLU[-2, 0, 2]:', act_relu[0], act_relu[2], act_relu[4]
PRINT, 'Expected: 0, 0, 2'
PRINT, ''

PRINT, 'Test 14: PReLU Activation (alpha=0.1)'
act_prelu = XDLMLAF_PRELU(act_test_data, 0.1)
PRINT, 'PReLU(-2) with alpha=0.1:', act_prelu[0], ' (expected -0.2)'
PRINT, 'PReLU(2):', act_prelu[4], ' (expected 2.0)'
PRINT, ''

PRINT, 'Test 15: ELU Activation (alpha=1.0)'
act_elu = XDLMLAF_ELU(act_test_data, 1.0)
PRINT, 'ELU(2):', act_elu[4], ' (expected 2.0)'
PRINT, 'ELU(-0.5):', act_elu[1], ' (expected -0.39)'
PRINT, ''

PRINT, 'Test 16: SoftPlus Activation'
act_softplus = XDLMLAF_SOFTPLUS(act_test_data)
PRINT, 'SoftPlus(0):', act_softplus[2], ' (expected 0.69)'
PRINT, 'SoftPlus(2):', act_softplus[4], ' (expected 2.13)'
PRINT, ''

PRINT, 'Test 17: SoftSign Activation'
act_softsign = XDLMLAF_SOFTSIGN(act_test_data)
PRINT, 'SoftSign(0):', act_softsign[2], ' (expected 0.0)'
PRINT, 'SoftSign(2):', act_softsign[4], ' (expected 0.67)'
PRINT, ''

PRINT, 'Test 18: Softmax Activation'
softmax_data = FLTARR(3)
softmax_data[0] = 1.0
softmax_data[1] = 2.0
softmax_data[2] = 3.0
act_softmax = XDLMLAF_SOFTMAX(softmax_data)
PRINT, 'Softmax[1,2,3]:', act_softmax[0], act_softmax[1], act_softmax[2]
sum_softmax = act_softmax[0] + act_softmax[1] + act_softmax[2]
PRINT, 'Sum (should be 1.0):', sum_softmax
PRINT, ''

PRINT, 'Test 19: ArcTan Activation'
act_arctan = XDLMLAF_ARCTAN(act_test_data)
PRINT, 'atan(0):', act_arctan[2], ' (expected 0.0)'
PRINT, 'atan(1):', act_arctan[3], ' (expected 0.46)'
PRINT, ''

PRINT, 'Test 20: Gaussian Activation'
act_gaussian = XDLMLAF_GAUSSIAN(act_test_data)
PRINT, 'Gaussian(0):', act_gaussian[2], ' (expected 1.0)'
PRINT, 'Gaussian(2):', act_gaussian[4], ' (expected 0.018)'
PRINT, ''

PRINT, 'Test 21: Sinc Activation'
act_sinc = XDLMLAF_SINC(act_test_data)
PRINT, 'Sinc(0):', act_sinc[2], ' (expected 1.0)'
PRINT, 'Sinc(2):', act_sinc[4], ' (expected 0.45)'
PRINT, ''

PRINT, 'Test 22: Sinusoid Activation'
act_sinusoid = XDLMLAF_SINUSOID(act_test_data)
PRINT, 'sin(0):', act_sinusoid[2], ' (expected 0.0)'
PRINT, 'sin(2):', act_sinusoid[4], ' (expected 0.91)'
PRINT, ''

; =========================================================================
; PHASE ML-2: LOSS FUNCTIONS
; =========================================================================
PRINT, '--- PHASE ML-2: LOSS FUNCTIONS ---'
PRINT, ''

y_true = FLTARR(5)
y_true[0] = 1.0
y_true[1] = 2.0
y_true[2] = 3.0
y_true[3] = 4.0
y_true[4] = 5.0

y_pred = FLTARR(5)
y_pred[0] = 1.1
y_pred[1] = 2.2
y_pred[2] = 2.9
y_pred[3] = 4.3
y_pred[4] = 4.8

PRINT, 'Test 23: Mean Squared Error'
mse = XDLMLLF_MEANSQUAREDERROR(y_true, y_pred)
PRINT, 'MSE:', mse, ' (expected 0.06)'
PRINT, ''

PRINT, 'Test 24: Mean Absolute Error'
mae = XDLMLLF_MEANABSOLUTEERROR(y_true, y_pred)
PRINT, 'MAE:', mae, ' (expected 0.18)'
PRINT, ''

PRINT, 'Test 25: Cross-Entropy Loss'
; Use probability-like values
y_true_prob = FLTARR(3)
y_true_prob[0] = 1.0
y_true_prob[1] = 0.0
y_true_prob[2] = 0.0
y_pred_prob = FLTARR(3)
y_pred_prob[0] = 0.7
y_pred_prob[1] = 0.2
y_pred_prob[2] = 0.1
ce = XDLMLLF_CROSSENTROPY(y_true_prob, y_pred_prob)
PRINT, 'CrossEntropy:', ce, ' (expected 0.12)'
PRINT, ''

PRINT, 'Test 26: Huber Loss (delta=1.0)'
huber = XDLMLLF_HUBER(y_true, y_pred, 1.0)
PRINT, 'Huber Loss:', huber, ' (should be between MAE and MSE)'
PRINT, ''

PRINT, 'Test 27: Log-Cosh Loss'
logcosh = XDLMLLF_LOGCOSH(y_true, y_pred)
PRINT, 'LogCosh Loss:', logcosh, ' (smooth approximation of MAE)'
PRINT, ''

; =========================================================================
; PHASE ML-3: OPTIMIZERS
; =========================================================================
PRINT, '--- PHASE ML-3: OPTIMIZERS ---'
PRINT, ''

weights = FLTARR(3)
weights[0] = 1.0
weights[1] = 2.0
weights[2] = 3.0

gradients = FLTARR(3)
gradients[0] = 0.1
gradients[1] = 0.2
gradients[2] = 0.3

PRINT, 'Test 28: Gradient Descent (lr=0.1)'
new_weights_gd = XDLMLOPT_GRADIENTDESCENT(weights, gradients, 0.1)
PRINT, 'Original weights:', weights[0], weights[1], weights[2]
PRINT, 'Updated weights:', new_weights_gd[0], new_weights_gd[1], new_weights_gd[2]
PRINT, 'Expected: 0.99, 1.98, 2.97'
PRINT, ''

PRINT, 'Test 29: Momentum Optimizer (lr=0.1, momentum=0.9)'
velocity = FLTARR(3)
velocity[0] = 0.0
velocity[1] = 0.0
velocity[2] = 0.0
new_weights_mom = XDLMLOPT_MOMENTUM(weights, gradients, velocity, 0.1, 0.9)
PRINT, 'Updated weights with momentum:', new_weights_mom[0], new_weights_mom[1], new_weights_mom[2]
PRINT, ''

PRINT, 'Test 30: RMSProp Optimizer (lr=0.1, decay=0.9)'
cache = FLTARR(3)
cache[0] = 0.01
cache[1] = 0.01
cache[2] = 0.01
new_weights_rms = XDLMLOPT_RMSPROP(weights, gradients, cache, 0.1, 0.9, 0.00000001)
PRINT, 'Updated weights with RMSProp:', new_weights_rms[0], new_weights_rms[1], new_weights_rms[2]
PRINT, ''

PRINT, 'Test 31: Adam Optimizer (lr=0.1, beta1=0.9, beta2=0.999)'
m = FLTARR(3)
m[0] = 0.0
m[1] = 0.0
m[2] = 0.0
v = FLTARR(3)
v[0] = 0.0
v[1] = 0.0
v[2] = 0.0
t = 1.0
new_weights_adam = XDLMLOPT_ADAM(weights, gradients, m, v, t, 0.1, 0.9, 0.999, 0.00000001)
PRINT, 'Updated weights with Adam:', new_weights_adam[0], new_weights_adam[1], new_weights_adam[2]
PRINT, ''

PRINT, 'Test 32: QuickProp Optimizer (lr=0.01, mu=1.75)'
prev_gradients = FLTARR(3)
prev_gradients[0] = 0.05
prev_gradients[1] = 0.15
prev_gradients[2] = 0.25
prev_step = FLTARR(3)
prev_step[0] = -0.01
prev_step[1] = -0.02
prev_step[2] = -0.03
new_weights_qp = XDLMLOPT_QUICKPROP(weights, gradients, prev_gradients, prev_step, 0.01, 1.75)
PRINT, 'Updated weights with QuickProp:', new_weights_qp[0], new_weights_qp[1], new_weights_qp[2]
PRINT, ''

; =========================================================================
; SUMMARY
; =========================================================================
PRINT, '========================================='
PRINT, 'Test Suite Complete!'
PRINT, '========================================='
PRINT, 'Functions Tested:'
PRINT, '  Phase ML-1: 8 functions (Data utils, Normalizers, K-means)'
PRINT, '  Phase ML-2: 17 Activation functions'
PRINT, '  Phase ML-2: 5 Loss functions'
PRINT, '  Phase ML-3: 5 Optimizer functions'
PRINT, ''
PRINT, 'Total: 35 ML functions tested successfully!'
PRINT, '========================================='
